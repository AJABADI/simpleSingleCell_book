[
["index.html", "Workflows for analyzing single-cell RNA-seq data with R/Bioconductor Chapter 1 Intro 1.1 Workflow version information 1.2 Motivation 1.3 scRNA-seq data analysis with Bioconductor 1.4 Obtaining a count matrix 1.5 Author information", " Workflows for analyzing single-cell RNA-seq data with R/Bioconductor Aaron T. L. Lun Cancer Research UK Cambridge Institute, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United KingdomDavis J. McCarthy EMBL European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge CB10 1SD, United KingdomJohn C. Marioni Cancer Research UK Cambridge Institute, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom2018-10-25 Chapter 1 Intro 1.1 Workflow version information R version: R version 3.5.0 (2018-04-23) Bioconductor version: 3.7 Package: 1.2.1 1.2 Motivation Single-cell RNA sequencing (scRNA-seq) is widely used to measure the genome-wide expression profile of individual cells. From each cell, mRNA is isolated and reverse transcribed to cDNA for high-throughput sequencing (Stegle, Teichmann, and Marioni 2015). This can be done using microfluidics platforms like the Fluidigm C1 (Pollen et al. 2014), protocols based on microtiter plates like Smart-seq2 (Picelli et al. 2014), or droplet-based technologies like inDrop (Klein et al. 2015; Macosko et al. 2015). The number of reads mapped to each gene is then used to quantify its expression in each cell. Alternatively, unique molecular identifiers (UMIs) can be used to directly measure the number of transcript molecules for each gene (Islam et al. 2014). Count data are analyzed to detect highly variable genes (HVGs) that drive heterogeneity across cells in a population, to find correlations between genes and cellular phenotypes, or to identify new subpopulations via dimensionality reduction and clustering. This provides biological insights at a single-cell resolution that cannot be achieved with conventional bulk RNA sequencing of cell populations. Strategies for scRNA-seq data analysis differ markedly from those for bulk RNA-seq. One technical reason is that scRNA-seq data are much noisier than bulk data (Brennecke et al. 2013; Marinov et al. 2014). Reliable capture (i.e., conversion) of transcripts into cDNA for sequencing is difficult with the low quantity of RNA in a single cell. This increases the frequency of drop-out events where none of the transcripts for a gene are captured. Dedicated steps are required to deal with this noise during analysis, especially during quality control. In addition, scRNA-seq data can be used to study cell-to-cell heterogeneity, e.g., to identify new cell subtypes, to characterize differentiation processes, to assign cells into their cell cycle phases, or to identify HVGs driving variability across the population (Vallejos, Marioni, and Richardson 2015; Fan et al. 2016; Trapnell et al. 2014). This is simply not possible with bulk data, meaning that custom methods are required to perform these analyses. 1.3 scRNA-seq data analysis with Bioconductor This package contains a set of computational workflows for basic analysis of scRNA-seq data, using software from the open-source Bioconductor project (Huber et al. 2015). The workflows start from a count matrix and describe a number of key steps for scRNA-seq data analysis, including quality control to remove problematic cells; normalization of cell-specific biases, with and without spike-ins; correction for batch effects; cell cycle phase classification from gene expression data; data exploration to identify putative subpopulations; and finally, HVG and marker gene identification to prioritize interesting genes. The application of these procedures will be demonstrated on several public scRNA-seq datasets involving immortalized myeloid progenitors, brain cells, haematopoietic stem cells, T-helper cells and mouse embryonic stem cells, generated with a range of experimental protocols and platforms (Lun et al. 2017; Wilson et al. 2015; Zeisel et al. 2015; Islam et al. 2011; Buettner et al. 2015; Zheng et al. 2017). The aim is to provide a variety of modular usage examples that can be applied to construct custom analysis pipelines. See the simpleSingleCell landing page for links to individual workflows and for instructions on how to install the required packages. To cite any of these workflows, please refer to http://f1000research.com/articles/5-2122/v2 for instructions. 1.4 Obtaining a count matrix All of these workflows start from a publicly available count matrix. For simplicity, we forego a description of the read processing steps required to generate the count matrix, i.e., read alignment and counting into features. These steps have been described in some detail elsewhere (Love et al. 2015; Chen, Lun, and Smyth 2016), and are largely the same for bulk and single-cell data. For users favouring an R-based approach to read alignment and counting, we suggest using the methods in the Rsubread package (Liao, Smyth, and Shi 2013, 2014). Some considerations specific to single-cell data may also be relevant, depending on the experimental protocol used to generate the data: If spike-in RNA was added, the sequences of the spike-in transcripts can be included as additional FASTA files during genome index building prior to alignment. Similarly, genomic intervals for both spike-in transcripts and endogenous genes can be concatenated into a single GTF file prior to counting. If UMIs are present, these should be extracted from the read sequence prior to alignment, e.g., with the UMI-tools software (Smith, Heger, and Sudbery 2017). Reads with the same UMI mapping to the same gene represent a single underlying transcript molecule and only increment the count of that gene by one. Alignment-free methods such as kallisto (Bray et al. 2016) or Salmon (Patro, Duggal, and Kingsford 2015) may also be useful, due to their speed and ability to perform transcript quantification. This can be loaded into R using methods from the tximport package (Soneson, Love, and Robinson 2015). 1.5 Author information 1.5.1 Author contributions A.T.L.L. developed and tested workflows on all datasets. A.T.L.L. and D.J.M. implemented improvements to the software packages required by the workflow. J.C.M. provided direction to the software and workflow development. All authors wrote and approved the final manuscript. 1.5.2 Competing interests No competing interests were disclosed. 1.5.3 Grant information A.T.L.L. and J.C.M. were supported by core funding from Cancer Research UK (award no. A17197). D.J.M. was supported by a CJ Martin Fellowship from the National Health and Medical Research Council of Australia. D.J.M and J.C.M. were also supported by core funding from EMBL. 1.5.4 Acknowledgements We would like to thank Antonio Scialdone for helpful discussions, as well as Michael Epstein, James R. Smith and John Wilson-Kanamori for testing the workflow on other datasets. References "],
["overview.html", "Chapter 2 Overview", " Chapter 2 Overview In this workflow, we use a relatively simple dataset (Lun et al. 2017) to introduce most of the concepts of scRNA-seq data analysis. This dataset contains two plates of 416B cells (an immortalized mouse myeloid progenitor cell line), processed using the Smart-seq2 protocol (Picelli et al. 2014). A constant amount of spike-in RNA from the External RNA Controls Consortium (ERCC) was also added to each cell’s lysate prior to library preparation. High-throughput sequencing was performed and the expression of each gene was quantified by counting the total number of reads mapped to its exonic regions. Similarly, the quantity of each spike-in transcript was measured by counting the number of reads mapped to the spike-in reference sequences. Counts for all genes/transcripts in each cell are available from ArrayExpress using the accession number E-MTAB-5522. We download both the count tables (in the “processed files”) as well as the metadata file using the BiocFileCache package. This saves the files to a local cache (raw_data) and avoids re-downloading them if they are already present. library(BiocFileCache) bfc &lt;- BiocFileCache(&quot;raw_data&quot;, ask = FALSE) lun.zip &lt;- bfcrpath(bfc, file.path(&quot;https://www.ebi.ac.uk/arrayexpress/files&quot;, &quot;E-MTAB-5522/E-MTAB-5522.processed.1.zip&quot;)) lun.sdrf &lt;- bfcrpath(bfc, file.path(&quot;https://www.ebi.ac.uk/arrayexpress/files&quot;, &quot;E-MTAB-5522/E-MTAB-5522.sdrf.txt&quot;)) unzip(lun.zip) References "],
["setting-up-the-data.html", "Chapter 3 Setting up the data 3.1 Loading in the count matrix 3.2 Incorporating cell-based annotation 3.3 Incorporating gene-based annotation", " Chapter 3 Setting up the data 3.1 Loading in the count matrix Our first task is to load the count matrices into memory. One matrix was generated for each plate of cells used in the study. In each matrix, each row represents an endogenous gene or a spike-in transcript, and each column represents a cell. Subsequently, the count in each entry of the matrix represents the number of reads mapped to a particular gene/transcript in a particular cell. plate1 &lt;- read.delim(&quot;counts_Calero_20160113.tsv&quot;, header=TRUE, row.names=1, check.names=FALSE) plate2 &lt;- read.delim(&quot;counts_Calero_20160325.tsv&quot;, header=TRUE, row.names=1, check.names=FALSE) gene.lengths &lt;- plate1$Length # First column is the gene length. plate1 &lt;- as.matrix(plate1[,-1]) # Discarding gene length (as it is not a cell). plate2 &lt;- as.matrix(plate2[,-1]) rbind(Plate1=dim(plate1), Plate2=dim(plate2)) ## [,1] [,2] ## Plate1 46703 96 ## Plate2 46703 96 We combine the two matrices into a single object for further processing. This is done after verifying that the genes are in the same order between the two matrices. stopifnot(identical(rownames(plate1), rownames(plate2))) all.counts &lt;- cbind(plate1, plate2) For convenience, the count matrix is stored in a SingleCellExperiment object from the SingleCellExperiment package. This allows different types of row- and column-level metadata to be stored alongside the counts for synchronized manipulation throughout the workflow. library(SingleCellExperiment) sce &lt;- SingleCellExperiment(list(counts=all.counts)) rowData(sce)$GeneLength &lt;- gene.lengths sce ## class: SingleCellExperiment ## dim: 46703 192 ## metadata(0): ## assays(1): counts ## rownames(46703): ENSMUSG00000102693 ENSMUSG00000064842 ... SIRV7 ## CBFB-MYH11-mcherry ## rowData names(1): GeneLength ## colnames(192): SLX-9555.N701_S502.C89V9ANXX.s_1.r_1 ## SLX-9555.N701_S503.C89V9ANXX.s_1.r_1 ... ## SLX-11312.N712_S508.H5H5YBBXX.s_8.r_1 ## SLX-11312.N712_S517.H5H5YBBXX.s_8.r_1 ## colData names(0): ## reducedDimNames(0): ## spikeNames(0): We identify the rows corresponding to ERCC spike-in transcripts from the row names. We store this information in the SingleCellExperiment object for future use. This is necessary as spike-ins require special treatment in downstream steps such as normalization. isSpike(sce, &quot;ERCC&quot;) &lt;- grepl(&quot;^ERCC&quot;, rownames(sce)) summary(isSpike(sce, &quot;ERCC&quot;)) ## Mode FALSE TRUE ## logical 46611 92 This dataset is slightly unusual in that it contains information from another set of spike-in transcripts, the Spike-In RNA Variants (SIRV) set. For simplicity, we will only use the ERCC spike-ins in this analysis. Thus, we must remove the rows corresponding to the SIRV transcripts prior to further analysis, which can be done simply by subsetting the SingleCellExperiment object. is.sirv &lt;- grepl(&quot;^SIRV&quot;, rownames(sce)) sce &lt;- sce[!is.sirv,] summary(is.sirv) ## Mode FALSE TRUE ## logical 46696 7 Comments from Aaron: Some feature-counting tools will report mapping statistics in the count matrix (e.g., the number of unaligned or unassigned reads). While these values can be useful for quality control, they would be misleading if treated as gene expression values. Thus, they should be removed (or at least moved to the colData) prior to further analyses. Be aware of using the ^ERCC regular expression for human data where the row names of the count matrix are gene symbols. An ERCC gene family actually exists in human annotation, so this would result in incorrect identification of genes as spike-in transcripts. This problem can be avoided by publishing count matrices with standard identifiers (e.g., Ensembl, Entrez). 3.2 Incorporating cell-based annotation We load in the metadata for each library/cell from the sdrf.txt file. It is important to check that the rows of the metadata table are in the same order as the columns of the count matrix. Otherwise, incorrect metadata will be assigned to each cell. metadata &lt;- read.delim(lun.sdrf, check.names=FALSE, header=TRUE) m &lt;- match(colnames(sce), metadata[[&quot;Source Name&quot;]]) # Enforcing identical order. stopifnot(all(!is.na(m))) # Checking that nothing&#39;s missing. metadata &lt;- metadata[m,] head(colnames(metadata)) ## [1] &quot;Source Name&quot; &quot;Comment[ENA_SAMPLE]&quot; ## [3] &quot;Comment[BioSD_SAMPLE]&quot; &quot;Characteristics[organism]&quot; ## [5] &quot;Characteristics[cell line]&quot; &quot;Characteristics[cell type]&quot; We only retain relevant metadata fields to avoid storing unnecessary information in the colData of the SingleCellExperiment object. In particular, we keep the plate of origin (i.e., block) and phenotype of each cell. The second field is relevant as all of the cells contain a CBFB-MYH11 oncogene, but the expression of this oncogene is only induced in a subset of the cells. colData(sce)$Plate &lt;- factor(metadata[[&quot;Factor Value[block]&quot;]]) pheno &lt;- metadata[[&quot;Factor Value[phenotype]&quot;]] levels(pheno) &lt;- c(&quot;induced&quot;, &quot;control&quot;) colData(sce)$Oncogene &lt;- pheno table(colData(sce)$Oncogene, colData(sce)$Plate) ## ## 20160113 20160325 ## induced 48 48 ## control 48 48 3.3 Incorporating gene-based annotation Feature-counting tools typically report genes in terms of standard identifiers from Ensembl or Entrez. These identifiers are used as they are unambiguous and highly stable. However, they are difficult to interpret compared to the gene symbols which are more commonly used in the literature. Given the Ensembl identifiers, we obtain the corresponding gene symbols using annotation packages like org.Mm.eg.db. library(org.Mm.eg.db) symb &lt;- mapIds(org.Mm.eg.db, keys=rownames(sce), keytype=&quot;ENSEMBL&quot;, column=&quot;SYMBOL&quot;) rowData(sce)$ENSEMBL &lt;- rownames(sce) rowData(sce)$SYMBOL &lt;- symb head(rowData(sce)) ## DataFrame with 6 rows and 3 columns ## GeneLength ENSEMBL SYMBOL ## &lt;integer&gt; &lt;character&gt; &lt;character&gt; ## 1 1070 ENSMUSG00000102693 NA ## 2 110 ENSMUSG00000064842 NA ## 3 6094 ENSMUSG00000051951 Xkr4 ## 4 480 ENSMUSG00000102851 NA ## 5 2819 ENSMUSG00000103377 NA ## 6 2233 ENSMUSG00000104017 NA It is often desirable to rename the row names of sce to the gene symbols, as these are easier to interpret. However, this requires some work to account for missing and duplicate symbols. The code below will replace missing symbols with the Ensembl identifier and concatenate duplicated symbols with the (unique) Ensembl identifiers. new.names &lt;- rowData(sce)$SYMBOL missing.name &lt;- is.na(new.names) new.names[missing.name] &lt;- rowData(sce)$ENSEMBL[missing.name] dup.name &lt;- new.names %in% new.names[duplicated(new.names)] new.names[dup.name] &lt;- paste0(new.names, &quot;_&quot;, rowData(sce)$ENSEMBL)[dup.name] rownames(sce) &lt;- new.names head(rownames(sce)) ## [1] &quot;ENSMUSG00000102693&quot; &quot;ENSMUSG00000064842&quot; &quot;Xkr4&quot; ## [4] &quot;ENSMUSG00000102851&quot; &quot;ENSMUSG00000103377&quot; &quot;ENSMUSG00000104017&quot; We also determine the chromosomal location for each gene using the TxDb.Mmusculus.UCSC.mm10.ensGene package. This will be useful later as several quality control metrics will be computed from rows corresponding to mitochondrial genes. library(TxDb.Mmusculus.UCSC.mm10.ensGene) location &lt;- mapIds(TxDb.Mmusculus.UCSC.mm10.ensGene, keys=rowData(sce)$ENSEMBL, column=&quot;CDSCHROM&quot;, keytype=&quot;GENEID&quot;) rowData(sce)$CHR &lt;- location summary(location==&quot;chrM&quot;) ## Mode FALSE TRUE NA&#39;s ## logical 22428 13 24255 Alternatively, annotation from BioMart resources can be directly added to the object using the getBMFeatureAnnos function from scater. This may be more convenient than the approach shown above, but depends on an available internet connection to the BioMart databases. "],
["quality-control-on-the-cells.html", "Chapter 4 Quality control on the cells 4.1 Defining the quality control metrics 4.2 Identifying outliers for each metric", " Chapter 4 Quality control on the cells 4.1 Defining the quality control metrics Low-quality cells need to be removed to ensure that technical effects do not distort downstream analysis results. We use several quality control (QC) metrics: The library size is defined as the total sum of counts across all features, i.e., genes and spike-in transcripts. Cells with small library sizes are of low quality as the RNA has not been efficiently captured (i.e., converted into cDNA and amplified) during library preparation. The number of expressed features in each cell is defined as the number of features with non-zero counts for that cell. Any cell with very few expressed genes is likely to be of poor quality as the diverse transcript population has not been successfully captured. The proportion of reads mapped to spike-in transcripts is calculated relative to the library size for each cell. High proportions are indicative of poor-quality cells, where endogenous RNA has been lost during processing (e.g., due to cell lysis or RNA degradation). The same amount of spike-in RNA to each cell, so an enrichment in spike-in counts is symptomatic of loss of endogenous RNA. In the absence of spike-in transcripts, the proportion of reads mapped to genes in the mitochondrial genome can also be used. High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane. For each cell, we calculate these quality control metrics using the calculateQCMetrics function from the scater package (McCarthy et al. 2017). These are stored in the row- and column-wise metadata of the SingleCellExperiment for future reference. library(scater) mito &lt;- which(rowData(sce)$CHR==&quot;chrM&quot;) sce &lt;- calculateQCMetrics(sce, feature_controls=list(Mt=mito)) head(colnames(colData(sce)), 10) ## [1] &quot;Plate&quot; &quot;Oncogene&quot; ## [3] &quot;is_cell_control&quot; &quot;total_features_by_counts&quot; ## [5] &quot;log10_total_features_by_counts&quot; &quot;total_counts&quot; ## [7] &quot;log10_total_counts&quot; &quot;pct_counts_in_top_50_features&quot; ## [9] &quot;pct_counts_in_top_100_features&quot; &quot;pct_counts_in_top_200_features&quot; The distributions of these metrics are shown in Figure 4.1, stratified by oncogene induction status and plate of origin. The aim is to remove putative low-quality cells that have low library sizes, low numbers of expressed features, and high spike-in (or mitochondrial) proportions. Such cells can interfere with downstream analyses, e.g., by forming distinct clusters that complicate interpretation of the results. sce$PlateOnco &lt;- paste0(sce$Oncogene, &quot;.&quot;, sce$Plate) multiplot( plotColData(sce, y=&quot;total_counts&quot;, x=&quot;PlateOnco&quot;), plotColData(sce, y=&quot;total_features_by_counts&quot;, x=&quot;PlateOnco&quot;), plotColData(sce, y=&quot;pct_counts_ERCC&quot;, x=&quot;PlateOnco&quot;), plotColData(sce, y=&quot;pct_counts_Mt&quot;, x=&quot;PlateOnco&quot;), cols=2) Figure 4.1: Distributions of various QC metrics for all cells in the 416B dataset. This includes the library sizes, number of expressed genes, and proportion of reads mapped to spike-in transcripts or mitochondrial genes. It is also valuable to examine how the QC metrics behave with respect to each other (Figure 4.2). Generally, they will be in rough agreement, i.e., cells with low total counts will also have low numbers of expressed features and high ERCC/mitochondrial proportions. Clear discrepancies may correspond to technical differences between batches of cells (see below) or genuine biological differences in RNA content. par(mfrow=c(1,3)) plot(sce$total_features_by_counts, sce$total_counts/1e6, xlab=&quot;Number of expressed genes&quot;, ylab=&quot;Library size (millions)&quot;) plot(sce$total_features_by_counts, sce$pct_counts_ERCC, xlab=&quot;Number of expressed genes&quot;, ylab=&quot;ERCC proportion (%)&quot;) plot(sce$total_features_by_counts, sce$pct_counts_Mt, xlab=&quot;Number of expressed genes&quot;, ylab=&quot;Mitochondrial proportion (%)&quot;) Figure 4.2: Behaviour of each QC metric compared to the total number of expressed features. Each point represents a cell in the 416B dataset. 4.2 Identifying outliers for each metric Picking a threshold for these metrics is not straightforward as their absolute values depend on the experimental protocol. For example, sequencing to greater depth will lead to more reads and more expressed features, regardless of the quality of the cells. Similarly, using more spike-in RNA in the protocol will result in higher spike-in proportions. To obtain an adaptive threshold, we assume that most of the dataset consists of high-quality cells, and identify cells that are outliers for the various QC metrics. Outliers are defined based on the median absolute deviation (MADs) from the median value of each metric across all cells. We remove cells with log-library sizes that are more than 3 MADs below the median log-library size. A log-transformation improves resolution at small values, especially when the MAD of the raw values is comparable to or greater than the median. We also remove cells where the log-transformed number of expressed genes is 3 MADs below the median value. libsize.drop &lt;- isOutlier(sce$total_counts, nmads=3, type=&quot;lower&quot;, log=TRUE, batch=sce$PlateOnco) feature.drop &lt;- isOutlier(sce$total_features_by_counts, nmads=3, type=&quot;lower&quot;, log=TRUE, batch=sce$PlateOnco) The batch= argument ensures that outliers are identified within each level of the specified plate/oncogene factor. This allows isOutlier() to accommodate systematic differences in the QC metrics across plates (Figure 4.1), which can arise due to technical differences in processing (e.g., differences in sequencing depth) rather than any changes in quality. The same reasoning applies to the oncogene induction status, where induced cells may have naturally fewer expressed genes for biological reasons. Failing to account for these systematic differences would inflate the MAD estimate and compromise the removal of low-quality cells. We identify outliers for the proportion-based metrics in a similar manner. Here, no transformation is required as we are identifying large outliers, for which the distinction should be fairly clear on the raw scale. We do not need to use the mitochondrial proportions as we already have the spike-in proportions (which serve a similar purpose) for this dataset. This avoids potential issues arising from genuine differences in mitochondrial content between cell types that may confound outlier identification. spike.drop &lt;- isOutlier(sce$pct_counts_ERCC, nmads=3, type=&quot;higher&quot;, batch=sce$PlateOnco) Subsetting by column will retain only the high-quality cells that pass each filter described above. We examine the number of cells removed by each filter as well as the total number of retained cells. Removal of a substantial proportion of cells (&gt; 10%) may be indicative of an overall issue with data quality. keep &lt;- !(libsize.drop | feature.drop | spike.drop) data.frame(ByLibSize=sum(libsize.drop), ByFeature=sum(feature.drop), BySpike=sum(spike.drop), Remaining=sum(keep)) ## ByLibSize ByFeature BySpike Remaining ## 1 5 4 6 183 We then subset the SingleCellExperiment object to retain only the putative high-quality cells. We also save the original object to file for later use. sce$PassQC &lt;- keep saveRDS(sce, file=&quot;416B_preQC.rds&quot;) sce &lt;- sce[,keep] dim(sce) ## [1] 46696 183 Comments from Aaron: See simpleSingleCell vignette for a more detailed discussion of the assumptions underlying the outlier-based detection of low-quality cells. isOutlier() will also return the exact filter thresholds for each metric (within each batch, if batch= is specified). These may be useful for checking whether the automatically selected thresholds are appropriate. attr(libsize.drop, &quot;thresholds&quot;) ## NULL attr(spike.drop, &quot;thresholds&quot;) ## NULL References "],
["classification-of-cell-cycle-phase.html", "Chapter 5 Classification of cell cycle phase", " Chapter 5 Classification of cell cycle phase We use the prediction method described by Scialdone et al. (2015) to classify cells into cell cycle phases based on the gene expression data. Using a training dataset, the sign of the difference in expression between two genes was computed for each pair of genes. Pairs with changes in the sign across cell cycle phases were chosen as markers. Cells in a test dataset can then be classified into the appropriate phase, based on whether the observed sign for each marker pair is consistent with one phase or another. This approach is implemented in the cyclone function from the scran package. The package contains a pre-trained set of marker pairs for mouse data, which we can load in the the readRDS function. We use the Ensembl identifiers for each gene in our dataset to match up with the names in the pre-trained set of gene pairs. set.seed(100) library(scran) mm.pairs &lt;- readRDS(system.file(&quot;exdata&quot;, &quot;mouse_cycle_markers.rds&quot;, package=&quot;scran&quot;)) assignments &lt;- cyclone(sce, mm.pairs, gene.names=rowData(sce)$ENSEMBL) The cyclone result for each cell in the HSC dataset is shown in Figure 5.1. Each cell is assigned a score for each phase, with a higher score corresponding to a higher probability that the cell is in that phase. We focus on the G1 and G2/M scores as these are the most informative for classification. plot(assignments$score$G1, assignments$score$G2M, xlab=&quot;G1 score&quot;, ylab=&quot;G2/M score&quot;, pch=16) Figure 5.1: Cell cycle phase scores from applying the pair-based classifier on the 416B dataset. Each point represents a cell, plotted according to its scores for G1 and G2/M phases. Cells are classified as being in G1 phase if the G1 score is above 0.5 and greater than the G2/M score; in G2/M phase if the G2/M score is above 0.5 and greater than the G1 score; and in S phase if neither score is above 0.5. Here, the vast majority of cells are classified as being in G1 phase. We save these assignments into the SingleCellExperiment object for later use. sce$phases &lt;- assignments$phases table(sce$phases) ## ## G1 G2M S ## 99 62 22 Pre-trained classifiers are available in scran for human and mouse data. While the mouse classifier used here was trained on data from embryonic stem cells, it is still accurate for other cell types (Scialdone et al. 2015). This may be due to the conservation of the transcriptional program associated with the cell cycle (Bertoli, Skotheim, and Bruin 2013; Conboy et al. 2007). The pair-based method is also a non-parametric procedure that is robust to most technical differences between datasets. Comments from Aaron: To remove confounding effects due to cell cycle phase, we can filter the cells to only retain those in a particular phase (usually G1) for downstream analysis. Alternatively, if a non-negligible number of cells are in other phases, we can use the assigned phase as a blocking factor. This protects against cell cycle effects without discarding information, and will be discussed later in more detail. The classifier may not be accurate for data that are substantially different from those used in the training set, e.g., due to the use of a different protocol. In such cases, users can construct a custom classifier from their own training data using the sandbag function. This will also be necessary for other model organisms where pre-trained classifiers are not available. Do not filter out low-abundance genes before applying cyclone. Even if a gene is not expressed in any cell, it may still be useful for classification if it is phase-specific. Its lack of expression relative to other genes will still yield informative pairs, and filtering them out would reduce power. References "],
["examining-gene-level-expression-metrics.html", "Chapter 6 Examining gene-level expression metrics 6.1 Inspecting the most highly expressed genes 6.2 Filtering out low-abundance genes", " Chapter 6 Examining gene-level expression metrics 6.1 Inspecting the most highly expressed genes We examine the identities of the most highly expressed genes (Figure 6.1). This should generally be dominated by constitutively expressed transcripts, such as those for ribosomal or mitochondrial proteins. The presence of other classes of features may be cause for concern if they are not consistent with expected biology. For example, a top set containing many spike-in transcripts suggests that too much spike-in RNA was added during library preparation, while the absence of ribosomal proteins and/or the presence of their pseudogenes are indicative of suboptimal alignment. fontsize &lt;- theme(axis.text=element_text(size=12), axis.title=element_text(size=16)) plotHighestExprs(sce, n=50) + fontsize Figure 6.1: Percentage of total counts assigned to the top 50 most highly-abundant features in the 416B dataset. For each feature, each bar represents the percentage assigned to that feature for a single cell, while the circle represents the average across all cells. Bars are coloured by the total number of expressed features in each cell, while circles are coloured according to whether the feature is labelled as a control feature. 6.2 Filtering out low-abundance genes Low-abundance genes are problematic as zero or near-zero counts do not contain much information for reliable statistical inference (Bourgon, Gentleman, and Huber 2010). These genes typically do not provide enough evidence to reject the null hypothesis during testing, yet they still increase the severity of the multiple testing correction. In addition, the discreteness of the counts may interfere with statistical procedures, e.g., by compromising the accuracy of continuous approximations. Thus, low-abundance genes are often removed in many RNA-seq analysis pipelines before the application of downstream methods. The “optimal” choice of filtering strategy depends on the downstream application. A more aggressive filter is usually required to remove discreteness (e.g., for normalization) compared to that required for removing underpowered tests. For hypothesis testing, the filter statistic should also be independent of the test statistic under the null hypothesis. Thus, we (or the relevant function) will filter at each step as needed, rather than applying a single filter for the entire analysis. Several metrics can be used to define low-abundance genes. The most obvious is the average count for each gene, computed across all cells in the dataset. We calculate this using the calcAverage() function, which also performs some adjustment for library size differences between cells. We typically observe a peak of moderately expressed genes following a plateau of lowly expressed genes (Figure 6.2). ave.counts &lt;- calcAverage(sce, use_size_factors=FALSE) hist(log10(ave.counts), breaks=100, main=&quot;&quot;, col=&quot;grey80&quot;, xlab=expression(Log[10]~&quot;average count&quot;)) Figure 6.2: Histogram of log-average counts for all genes in the 416B dataset. A minimum threshold can be applied to this value to filter out genes that are lowly expressed. The example below demonstrates how we could remove genes with average counts less than 1. The number of TRUE values in demo.keep corresponds to the number of retained rows/genes after filtering. demo.keep &lt;- ave.counts &gt;= 1 filtered.sce &lt;- sce[demo.keep,] summary(demo.keep) ## Mode FALSE TRUE ## logical 33490 13206 We also examine the number of cells that express each gene. This is closely related to the average count for most genes, as expression in many cells will result in a higher average (Figure 6.3). Genes expressed in very few cells are often uninteresting as they are driven by amplification artifacts (though they may also also arise from rare populations). We could then remove genes that are expressed in fewer than n cells. num.cells &lt;- nexprs(sce, byrow=TRUE) smoothScatter(log10(ave.counts), num.cells, ylab=&quot;Number of cells&quot;, xlab=expression(Log[10]~&quot;average count&quot;)) Figure 6.3: The number of cells expressing each gene in the 416B dataset, plotted against the log-average count. Intensity of colour corresponds to the number of genes at any given location. As mentioned above, we will apply these filters at each step rather than applying them globally by subsetting sce. This ensures that the most appropriate filter is used in each application. Nonetheless, we remove genes that are not expressed in any cell to reduce computational work in downstream steps. Such genes provide no information and would be removed by any filtering strategy. to.keep &lt;- num.cells &gt; 0 sce &lt;- sce[to.keep,] summary(to.keep) ## Mode FALSE TRUE ## logical 22833 23863 References "],
["normalization-of-cell-specific-biases.html", "Chapter 7 Normalization of cell-specific biases 7.1 Using the deconvolution method to deal with zero counts 7.2 Computing separate size factors for spike-in transcripts 7.3 Applying the size factors to normalize gene expression", " Chapter 7 Normalization of cell-specific biases 7.1 Using the deconvolution method to deal with zero counts Read counts are subject to differences in capture efficiency and sequencing depth between cells (Stegle, Teichmann, and Marioni 2015). Normalization is required to eliminate these cell-specific biases prior to downstream quantitative analyses. This is often done by assuming that most genes are not differentially expressed (DE) between cells. Any systematic difference in count size across the non-DE majority of genes between two cells is assumed to represent bias and is removed by scaling. More specifically, “size factors” are calculated that represent the extent to which counts should be scaled in each library. Size factors can be computed with several different approaches, e.g., using the estimateSizeFactorsFromMatrix function in the DESeq2 package (Anders and Huber 2010; Love, Huber, and Anders 2014), or with the calcNormFactors function (Robinson and Oshlack 2010) in the edgeR package. However, single-cell data can be problematic for these bulk data-based methods due to the dominance of low and zero counts. To overcome this, we pool counts from many cells to increase the count size for accurate size factor estimation (Lun, Bach, and Marioni 2016). Pool-based size factors are then “deconvolved” into cell-based factors for cell-specific normalization. sce &lt;- computeSumFactors(sce) summary(sizeFactors(sce)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.3416 0.7229 0.9245 1.0000 1.1483 3.5925 The size factors are well-correlated with the library sizes for all cells (Figure 7.1). This suggests that most of the systematic differences between cells are driven by differences in capture efficiency or sequencing depth. Any DE between cells would yield a non-linear trend between the total count and size factor, and/or increased scatter around the trend. We observe some evidence of this after oncogene induction, where the size factors after induction are systematically lower. This is consistent with composition biases (Robinson and Oshlack 2010) introduced by upregulation of genes after induction. plot(sce$total_counts/1e6, sizeFactors(sce), log=&quot;xy&quot;, xlab=&quot;Library size (millions)&quot;, ylab=&quot;Size factor&quot;, col=c(&quot;red&quot;, &quot;black&quot;)[sce$Oncogene], pch=16) legend(&quot;bottomright&quot;, col=c(&quot;red&quot;, &quot;black&quot;), pch=16, cex=1.2, legend=levels(sce$Oncogene)) Figure 7.1: Size factors from deconvolution, plotted against library sizes for all cells in the 416B dataset. Axes are shown on a log-scale. Wild-type cells are shown in black and oncogene-induced cells are shown in red. Comments from Aaron: While the deconvolution approach is robust to the high frequency of zeroes in scRNA-seq data, it will eventually fail if too many counts are zero. This manifests as negative size factors that are obviously nonsensical. To avoid this, the computeSumFactors function will automatically remove low-abundance genes prior to the calculation of size factors. Genes with a library size-adjusted average count below a specified threshold (min.mean) are ignored. For read count data, the default value of 1 is usually satisfactory. For UMI data, counts are lower so a threshold of 0.1 is recommended. While the library size-adjusted average is not entirely independent of the bias (Bourgon, Gentleman, and Huber 2010), this is a better filter statistic than the sample mean count. The latter would enrich for genes that are upregulated in cells with large library sizes, resulting in inflated size factor estimates for those cells. Cell-based QC should always be performed prior to normalization, to remove cells with very low numbers of expressed genes. Otherwise, computeSumFactors() may yield negative size factors for low-quality cells. This is because too many zeroes are present in these cells, reducing the effectiveness of pooling to eliminate zeroes. Indeed, for some low-quality cells, the effect of cell damage on the transcriptome may already violate the non-DE assumption. The sizes argument can be used to specify the number of pool sizes to use to compute the size factors. More sizes yields more precise estimates at the cost of some computational time and memory. In general, all sizes should not above 20 cells to ensure that there are sufficient non-zero expression values in each pool. The total number of cells should also be at least 100 for effective pooling. For highly heterogeneous datasets, it is advisable to perform a rough clustering of the cells. This can be done with the quickCluster function and the results passed to computeSumFactors via the cluster argument. Cells in each cluster are normalized separately, and the size factors are rescaled to be comparable across clusters. This avoids the need to assume that most genes are non-DE across the entire population - only a non-DE majority is required between pairs of clusters. We demonstrate this approach later with a larger dataset in the next workflow. 7.2 Computing separate size factors for spike-in transcripts Size factors computed from the counts for endogenous genes are usually not appropriate for normalizing the counts for spike-in transcripts. Consider an experiment without library quantification, i.e., the amount of cDNA from each library is not equalized prior to pooling and multiplexed sequencing. Here, cells containing more RNA have greater counts for endogenous genes and thus larger size factors to scale down those counts. However, the same amount of spike-in RNA is added to each cell during library preparation. This means that the counts for spike-in transcripts are not subject to the effects of RNA content. Attempting to normalize the spike-in counts with the gene-based size factors will lead to over-normalization and incorrect quantification of expression. Similar reasoning applies in cases where library quantification is performed. For a constant total amount of cDNA, any increases in endogenous RNA content will suppress the coverage of spike-in transcripts. As a result, the bias in the spike-in counts will be opposite to that captured by the gene-based size factor. To ensure normalization is performed correctly, we compute a separate set of size factors for the spike-in set. For each cell, the spike-in-specific size factor is defined as the total count across all transcripts in the spike-in set. This assumes that none of the spike-in transcripts are differentially expressed, which is reasonable given that the same amount and composition of spike-in RNA should have been added to each cell (Lun et al. 2017). (See below for a more detailed discussion on spike-in normalization.) These size factors are stored in a separate field of the SingleCellExperiment object by setting general.use=FALSE in computeSpikeFactors. This ensures that they will only be used with the spike-in transcripts but not the endogenous genes. sce &lt;- computeSpikeFactors(sce, type=&quot;ERCC&quot;, general.use=FALSE) 7.3 Applying the size factors to normalize gene expression The count data are used to compute normalized log-expression values for use in downstream analyses. Each value is defined as the log2-ratio of each count to the size factor for the corresponding cell, after adding a prior count of 1 to avoid undefined values at zero counts. Division by the size factor ensures that any cell-specific biases are removed. If spike-in-specific size factors are present in sce, they will be automatically applied to normalize the spike-in transcripts separately from the endogenous genes. sce &lt;- normalize(sce) The log-transformation is useful as it means that any differences in the values directly represent log2-fold changes in expression between cells. This is usually more relevant than the absolute differences in coverage, which need to be interpreted in the context of the overall abundance. The log-transformation also provides some measure of variance stabilization (Law et al. 2014), so that high-abundance genes with large variances do not dominate downstream analyses. The computed values are stored as an &quot;logcounts&quot; matrix in addition to the other assay elements. References "],
["modelling-the-technical-noise-in-gene-expression.html", "Chapter 8 Modelling the technical noise in gene expression", " Chapter 8 Modelling the technical noise in gene expression Variability in the observed expression values across genes can be driven by genuine biological heterogeneity or uninteresting technical noise. To distinguish between these two possibiltiies, we need to model the technical component of the variance of the expression values for each gene. We do so using the set of spike-in transcripts, which were added in the same quantity to each cell. Thus, the spike-in transcripts should exhibit no biological variability, i.e., any variance in their counts should be technical in origin. We use the trendVar() function to fit a mean-dependent trend to the variances of the log-expression values for the spike-in transcripts. We set block= to block on the plate of origin for each cell, to ensure that technical differences between plates do not inflate the variances. Given the mean abundance of a gene, the fitted value of the trend is then used as an estimate of the technical component for that gene. The biological component of the variance is finally calculated by subtracting the technical component from the total variance of each gene with the decomposeVar function. var.fit &lt;- trendVar(sce, parametric=TRUE, block=sce$Plate, loess.args=list(span=0.3)) var.out &lt;- decomposeVar(sce, var.fit) head(var.out) ## DataFrame with 6 rows and 6 columns ## mean total ## &lt;numeric&gt; &lt;numeric&gt; ## ENSMUSG00000103377 0.00801037877839526 0.0117416958615873 ## ENSMUSG00000103147 0.0344865345591075 0.0716382020605793 ## ENSMUSG00000103161 0.00521187224764422 0.004971239574775 ## ENSMUSG00000102331 0.0185051179446466 0.0323577082946858 ## ENSMUSG00000102948 0.0591783482173367 0.0886595415581617 ## Rp1 0.0972805805064885 0.454538935512767 ## bio tech ## &lt;numeric&gt; &lt;numeric&gt; ## ENSMUSG00000103377 -0.0237346026365764 0.0354762984981637 ## ENSMUSG00000103147 -0.0811139104461332 0.152752112506713 ## ENSMUSG00000103161 -0.0181138443394628 0.0230850839142378 ## ENSMUSG00000102331 -0.049601656974152 0.0819593652688378 ## ENSMUSG00000102948 -0.173456540044603 0.262116081602765 ## Rp1 0.0236757758027058 0.430863159710061 ## p.value FDR ## &lt;numeric&gt; &lt;numeric&gt; ## ENSMUSG00000103377 1 1 ## ENSMUSG00000103147 0.999999999993329 1 ## ENSMUSG00000103161 1 1 ## ENSMUSG00000102331 0.999999999998749 1 ## ENSMUSG00000102948 1 1 ## Rp1 0.0345090750415943 0.150289201925332 We visually inspect the trend to confirm that it corresponds to the spike-in variances (Figure 8.1)). The wave-like shape is typical of the mean-variance trend for log-expression values. A linear increase in the variance is observed as the mean increases from zero, as larger variances are possible when the counts increase. At very high abundances, the effect of sampling noise decreases due to the law of large numbers, resulting in a decrease in the variance. plot(var.out$mean, var.out$total, pch=16, cex=0.6, xlab=&quot;Mean log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curve(var.fit$trend(x), col=&quot;dodgerblue&quot;, lwd=2, add=TRUE) cur.spike &lt;- isSpike(sce) points(var.out$mean[cur.spike], var.out$total[cur.spike], col=&quot;red&quot;, pch=16) Figure 8.1: Variance of normalized log-expression values for each gene in the 416B dataset, plotted against the mean log-expression. The blue line represents the mean-dependent trend fitted to the variances of the spike-in transcripts (red). We check the distribution of expression values for the genes with the largest biological components. This ensures that the variance estimate is not driven by one or two outlier cells (Figure 8.2). chosen.genes &lt;- order(var.out$bio, decreasing=TRUE)[1:10] plotExpression(sce, features=rownames(var.out)[chosen.genes]) + fontsize Figure 8.2: Violin plots of normalized log-expression values for the top 10 genes with the largest biological components in the 416B dataset. Each point represents the log-expression value in a single cell. Comments from Aaron: In practice, trend fitting is complicated by the small number of spike-in transcripts and the uneven distribution of their abundances. See the simpleSingleCell vignette for more details on how to refine the fit. In the absence of spike-ins, users can set use.spikes=FALSE to fit a trend to the variances of the endogenous genes (see simpleSingleCell vignette). Alternatively, we can create a trend based on the assumption of Poisson technical noise, as described in the vignette. Negative biological components are often obtained from decomposeVar. These are intuitively meaningless as it is impossible for a gene to have total variance below technical noise. Nonetheless, such values occur due to imprecise estimation of the total variance, especially for low numbers of cells. decomposeVar also yields p-values that can be used to define HVGs at a specific threshold for the false discovery rate (FDR). We will discuss this in more detail later, as formal detection of HVGs is not necessary for feature selection during data exploration. "],
["removing-the-batch-effect.html", "Chapter 9 Removing the batch effect", " Chapter 9 Removing the batch effect As previously mentioned, the data were collected on two plates. Small uncontrollable differences in processing between plates can result in a batch effect, i.e., systematic differences in expression between cells on different plates. Such differences are not interesting and can be removed by applying the removeBatchEffect() function from the limma package (Ritchie et al. 2015). This removes the effect of the plate of origin while accounting for the (interesting) effect of oncogene induction. library(limma) assay(sce, &quot;corrected&quot;) &lt;- removeBatchEffect(logcounts(sce), design=model.matrix(~sce$Oncogene), batch=sce$Plate) assayNames(sce) ## [1] &quot;counts&quot; &quot;logcounts&quot; &quot;corrected&quot; Manual batch correction is necessary for downstream procedures that are not model-based, e.g., clustering and most forms of dimensionality reduction. However, if an analysis method can accept a design matrix, blocking on nuisance factors in the design matrix is preferable to using removeBatchEffect(). This is because the latter does not account for the loss of residual degrees of freedom, nor the uncertainty of estimation of the blocking factor terms. Comments from Aaron: removeBatchEffect() performs a linear regression and sets the coefficients corresponding to the blocking factors to zero. This is effective provided that the population composition within each batch is known (and supplied as design=) or identical across batches. Such an assumption is reasonable for this dataset, involving a homogeneous cell line population on both plates. However, in most scRNA-seq applications, the factors of variation are not identical across batches and not known in advance. This motivates the use of more sophisticated batch correction methods such as mnnCorrect(). References "],
["denoising-expression-values-using-pca.html", "Chapter 10 Denoising expression values using PCA", " Chapter 10 Denoising expression values using PCA Once the technical noise is modelled, we can use principal components analysis (PCA) to remove random technical noise. Consider that each cell represents a point in the high-dimensional expression space, where the spread of points represents the total variance. PCA identifies axes in this space that capture as much of this variance as possible. Each axis is a principal component (PC), where any early PC will explain more of the variance than a later PC. We assume that biological processes involving co-regulated groups of genes will account for the most variance in the data. If this is the case, this process should be represented by one or more of the earlier PCs. In contrast, random technical noise affects each gene independently and will be represented by later PCs. The denoisePCA() function removes later PCs until the total discarded variance is equal to the sum of technical components for all genes used in the PCA. sce &lt;- denoisePCA(sce, technical=var.out, assay.type=&quot;corrected&quot;) dim(reducedDim(sce, &quot;PCA&quot;)) ## [1] 183 24 The function returns a SingleCellExperiment object containing the PC scores for each cell in the reducedDims slot. The aim is to eliminate technical noise and enrich for biological signal in the retained PCs. This improves resolution of the underlying biology during downstream procedures such as clustering. Comments from Aaron: denoisePCA() will only use genes that have positive biological components, i.e., variances greater than the fitted trend. This guarantees that the total technical variance to be discarded will not be greater than the total variance in the data. For the technical= argument, the function will also accept the trend function directly (i.e., var.fit$trend) or a vector of technical components per gene. Here, we supply the DataFrame from decomposeVar() to allow the function to adjust for the loss of residual degrees of freedom after batch correction. Specifically, the variance in the batch-corrected matrix is slightly understated, requiring some rescaling of the technical components to compensate. No filtering is performed on abundance here, which ensures that PCs corresponding to rare subpopulations can still be detected. Discreteness is less of an issue as low-abundance genes also have lower variance, thus reducing their contribution to the PCA. It is also possible to obtain a low-rank approximation of the original expression matrix, capturing the variance equivalent to the retained PCs. This is useful for denoising prior to downstream procedures that require gene-wise expression values. sce2 &lt;- denoisePCA(sce, technical=var.fit$trend, assay.type=&quot;corrected&quot;, value=&quot;lowrank&quot;) assayNames(sce2) ## [1] &quot;counts&quot; &quot;logcounts&quot; &quot;corrected&quot; &quot;lowrank&quot; "],
["visualizing-data-in-low-dimensional-space.html", "Chapter 11 Visualizing data in low-dimensional space 11.1 With PCA 11.2 With t-SNE", " Chapter 11 Visualizing data in low-dimensional space 11.1 With PCA We visualize the relationships between cells by constructing pairwise PCA plots for the first three components (Figure 11.1). Cells with similar expression profiles should be located close together in the plot, while dissimilar cells should be far apart. In this case, we observe a clear separation of cells based on the oncogene induction status, consistent with the expected effects on the transcriptome. plotReducedDim(sce, use_dimred=&quot;PCA&quot;, ncomponents=3, colour_by=&quot;Oncogene&quot;) + fontsize Figure 11.1: Pairwise PCA plots of the first three PCs in the 416B dataset, constructed from normalized log-expression values of genes with positive biological components. Each point represents a cell, coloured according to oncogene induction status. By comparison, we observe no clear separation of cells by batch (Figure 11.2). This indicates that our batch correction step using removeBatchEffect() was successful. plotReducedDim(sce, use_dimred=&quot;PCA&quot;, ncomponents=3, colour_by=&quot;Plate&quot;) + fontsize Figure 11.2: Pairwise PCA plots of the first three PCs in the 416B dataset, constructed from normalized log-expression values of genes with positive biological components. Each point represents a cell, coloured according to the plate of origin. Note that plotReducedDim() will use the PCA results that were already stored in sce by denoisePCA(). This allows us to rapidly generate new plots with different aesthetics, without repeating the entire PCA computation. Similarly, plotPCA() will use existing results if they are available in the SingleCellExperiment, and will recalculate them otherwise. Users should set rerun=TRUE to forcibly recalculate the PCs in the presence of existing results. Comments from Aaron: For each visualization method, additional cell-specific information can be incorporated into the size or shape of each point. This is done using the size_by= and shape_by= arguments in most plotting functions. More components can be shown but these are usually less informative as they explain less of the variance. They are also often more difficult to interpret as they are defined to be orthogonal to earlier PCs (and thus dependent on what is detected in those PCs). 11.2 With t-SNE Another widely used approach for dimensionality reduction is the t-stochastic neighbour embedding (t-SNE) method (Van der Maaten and Hinton 2008). t-SNE tends to work better than PCA for separating cells in more diverse populations. This is because the former can directly capture non-linear relationships in high-dimensional space, whereas the latter must represent them on linear axes. However, this improvement comes at the cost of more computational effort and requires the user to consider parameters such as the random seed and perplexity (see comments). We demonstrate the generation of t-SNE plots in Figure 11.3 using the plotTSNE() function. We set use_dimred=&quot;PCA&quot; to perform the t-SNE on the low-rank approximation of the data, allowing the algorithm to take advantage of the previous denoising step. set.seed(100) out5 &lt;- plotTSNE(sce, run_args=list(use_dimred=&quot;PCA&quot;, perplexity=5), colour_by=&quot;Oncogene&quot;) + fontsize + ggtitle(&quot;Perplexity = 5&quot;) set.seed(100) out10 &lt;- plotTSNE(sce, run_args=list(use_dimred=&quot;PCA&quot;, perplexity=10), colour_by=&quot;Oncogene&quot;) + fontsize + ggtitle(&quot;Perplexity = 10&quot;) set.seed(100) out20 &lt;- plotTSNE(sce, run_args=list(use_dimred=&quot;PCA&quot;, perplexity=20), colour_by=&quot;Oncogene&quot;) + fontsize + ggtitle(&quot;Perplexity = 20&quot;) multiplot(out5, out10, out20, cols=3) Figure 11.3: t-SNE plots constructed from the denoised PCs in the 416B dataset, using a range of perplexity values. Each point represents a cell, coloured according to its oncogene induction status. Bars represent the coordinates of the cells on each axis. t-SNE is a stochastic method, so users should run the algorithm several times to ensure that the results are representative. Scripts should set a seed (via the set.seed() command) to ensure that the chosen results are reproducible. It is also advisable to test different settings of the “perplexity” parameter as this will affect the distribution of points in the low-dimensional space. Here, we call runTSNE() with a perplexity of 20 to store the t-SNE results inside our SingleCellExperiment object. This avoids repeating the calculations whenever we want to create a new plot with plotTSNE(), as the stored results will be used instead. Again, users can set rerun=TRUE to force recalculation in the presence of stored results. set.seed(100) sce &lt;- runTSNE(sce, use_dimred=&quot;PCA&quot;, perplexity=20) reducedDimNames(sce) ## [1] &quot;PCA&quot; &quot;TSNE&quot; There are many other dimensionality reduction techniques that we do not consider here but could also be used, e.g., multidimensional scaling, diffusion maps. These have their own advantages and disadvantages – for example, diffusion maps (see plotDiffusionMap) place cells along a continuous trajectory and are suited for visualizing graduated processes like differentiation (Angerer et al. 2016). Comments from Aaron: A good guide on how to interpret t-SNE plots can be found at http://distill.pub/2016/misread-tsne/. This demonstrates how distances between clusters in the 2-dimensional embedding have little meaning, as does the apparent “size” (i.e., spread) of the clusters. References "],
["clustering-cells-into-putative-subpopulations.html", "Chapter 12 Clustering cells into putative subpopulations 12.1 Defining cell clusters from expression data 12.2 Detecting marker genes between clusters", " Chapter 12 Clustering cells into putative subpopulations 12.1 Defining cell clusters from expression data The denoised log-expression values are used to cluster cells into putative subpopulations. Specifically, we perform hierarchical clustering on the Euclidean distances between cells, using Ward’s criterion to minimize the total variance within each cluster. This yields a dendrogram that groups together cells with similar expression patterns across the chosen genes. pcs &lt;- reducedDim(sce, &quot;PCA&quot;) my.dist &lt;- dist(pcs) my.tree &lt;- hclust(my.dist, method=&quot;ward.D2&quot;) Clusters are explicitly defined by applying a dynamic tree cut (Langfelder, Zhang, and Horvath 2008) to the dendrogram. This exploits the shape of the branches in the dendrogram to refine the cluster definitions, and is more appropriate than cutree for complex dendrograms. Greater control of the empirical clusters can be obtained by manually specifying cutHeight in cutreeDynamic. We also set minClusterSize to a lower value than the default of 20, to avoid spurious aggregation of distant small clusters. library(dynamicTreeCut) my.clusters &lt;- unname(cutreeDynamic(my.tree, distM=as.matrix(my.dist), minClusterSize=10, verbose=0)) We examine the distribution of cells in each cluster with respect to known factors. Each cluster is comprised of cells from both batches, indicating that the clustering is not driven by a batch effect. Differences in the composition of each cluster are observed with respect to Oncogene, consistent with a biological effect of oncogene induction. table(my.clusters, sce$Plate) ## ## my.clusters 20160113 20160325 ## 1 40 39 ## 2 19 17 ## 3 16 14 ## 4 10 14 ## 5 6 8 table(my.clusters, sce$Oncogene) ## ## my.clusters induced control ## 1 79 0 ## 2 0 36 ## 3 0 30 ## 4 0 24 ## 5 14 0 We visualize the cluster assignments for all cells on the t-SNE plot in Figure 12.1. Adjacent cells are generally assigned to the same cluster, indicating that the clustering procedure was applied correctly. sce$cluster &lt;- factor(my.clusters) plotTSNE(sce, colour_by=&quot;cluster&quot;) + fontsize Figure 12.1: t-SNE plot of the denoised PCs of the 416B dataset. Each point represents a cell and is coloured according to the cluster identity to which it was assigned. We check the separatedness of the clusters using the silhouette width (Figure 12.2). Cells with large positive silhouette widths are closer to other cells in the same cluster than to cells in different clusters. Conversely, cells with negative widths are closer to other clusters than to other cells in the cluster to which it was assigned. Each cluster would ideally contain many cells with large positive widths, indicating that it is well-separated from other clusters. library(cluster) clust.col &lt;- scater:::.get_palette(&quot;tableau10medium&quot;) # hidden scater colours sil &lt;- silhouette(my.clusters, dist = my.dist) sil.cols &lt;- clust.col[ifelse(sil[,3] &gt; 0, sil[,1], sil[,2])] sil.cols &lt;- sil.cols[order(-sil[,1], sil[,3])] plot(sil, main = paste(length(unique(my.clusters)), &quot;clusters&quot;), border=sil.cols, col=sil.cols, do.col.sort=FALSE) Figure 12.2: Barplot of silhouette widths for cells in each cluster. Each cluster is assigned a colour and cells with positive widths are coloured according to the colour of its assigned cluster. Any cell with a negative width is coloured according to the colour of the cluster that it is closest to. The average width for all cells in each cluster is shown, along with the average width for all cells in the dataset. The silhouette width can be used to determine the parameter values that maximize the separation between clusters. For example, we could vary the cut height or splitting depth in cutreeDynamic to maximize the average silhouette width across all cells. This usually provides a satisfactory initial clustering for further examination. However, keep in mind that the granularity of clustering is much like the magnification on a microscope. Different views of the data can be obtained with different granularities, some of which may be suboptimal on measures of separation. Users should not fixate on the clustering with the greatest separation if it does not provide the desired granularity for a particular biological question. Most cells have relatively small silhouette positive widths in Figure 12.2, indicating that the separation between clusters is weak. This may be symptomatic of over-clustering where clusters that are clearly defined on oncogene induction status are further split into subsets that are less well separated. Nonetheless, we will proceed with the current clustering scheme in my.clusters, as it provides reasonable partitions for further characterization of heterogeneity. Comments from Aaron: An alternative clustering strategy is to use a matrix of distances derived from correlations (e.g., as in quickCluster). This is more robust to noise and normalization errors, but is also less sensitive to subtle changes in the expression profiles. Both Ward’s criterion and complete linkage yield spherical, compact clusters. In particular, complete linkage favours the formation of clusters with the same diameter. This may be desirable in some cases but is less appropriate when subpopulations differ in their variance. Thus, we typically use Ward’s criterion for our initial clustering. Of course, it is simple (and recommended) to try other approaches provided that some assessment is performed, e.g., using the silhouette width. 12.2 Detecting marker genes between clusters Once putative subpopulations are identified by clustering, we can identify marker genes for each cluster using the findMarkers function. This performs Welch \\(t\\)-tests on the log-expression values for every gene and between every pair of clusters (Soneson and Robinson 2018). The aim is to test for DE in each cluster compared to the others while blocking on uninteresting factors such as the plate of origin. The top DE genes are likely to be good candidate markers as they can effectively distinguish between cells in different clusters. markers &lt;- findMarkers(sce, my.clusters, block=sce$Plate) For each cluster, the DE results of the relevant comparisons are consolidated into a single output table. This allows a set of marker genes to be easily defined by taking the top DE genes from each pairwise comparison between clusters. For example, to construct a marker set for cluster 1 from the top 10 genes of each comparison, one would filter marker.set to retain rows with Top less than or equal to 10. Other statistics are also reported for each gene, including the adjusted p-values (see below) and the log-fold changes relative to every other cluster. marker.set &lt;- markers[[&quot;1&quot;]] head(marker.set, 10) ## DataFrame with 10 rows and 6 columns ## Top FDR logFC.2 logFC.3 ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## Aurkb 1 3.57731459036545e-32 -7.39137048940061 -6.77227082342766 ## Tk1 1 6.14583238348605e-29 -4.79357274943543 -7.610521944668 ## Cdca8 1 6.27977508120356e-23 -6.98353186925976 -5.14867209037853 ## Myh11 1 7.46521687382308e-22 4.37714191593754 4.37854437192151 ## Ccna2 2 1.80015331041228e-29 -7.4330496627687 -7.08153074893503 ## Pclaf 2 2.31327100093205e-25 -5.56714921671886 -7.57990988274836 ## Cks1b 2 2.06467827649085e-18 -6.81767090676048 -6.04001181928717 ## Pirb 2 2.50560067866424e-15 5.19604859960812 5.24523582985688 ## Ube2c 3 4.84313636309891e-28 -7.94593152928904 -4.23898926544224 ## Rrm2 3 1.52352395791045e-24 -5.45829619585342 -7.75339990141175 ## logFC.4 logFC.5 ## &lt;numeric&gt; &lt;numeric&gt; ## Aurkb -1.95145075542623 -6.41735160332462 ## Tk1 -3.52963403498811 -4.24172385898634 ## Cdca8 -2.52622785978127 -7.26824410188525 ## Myh11 4.45150905933443 0.9387643805397 ## Ccna2 -2.55994736892407 -7.31965669537105 ## Pclaf -2.4323481751295 -5.2901842158707 ## Cks1b -4.45638344358755 -6.40480503325219 ## Pirb 5.86618518791929 -0.0110358172874627 ## Ube2c -2.14802144694623 -6.67791590516897 ## Rrm2 -3.18046561232799 -4.95579772214588 We save the list of candidate marker genes for further examination. write.table(marker.set, file=&quot;416B_marker_1.tsv&quot;, sep=&quot;\\t&quot;, quote=FALSE, col.names=NA) We visualize the expression profiles of the top candidates to verify that the DE signature is robust (Figure 12.3). Most of the top markers have strong and consistent up- or downregulation in cells of cluster 1 compared to some or all of the other clusters. A cursory examination of the heatmap indicates that cluster 1 contains oncogene-induced cells with strong downregulation of DNA replication and cell cycle genes. This is consistent with the potential induction of senescence as an anti-tumorigenic response (Wajapeyee et al. 2010). A more comprehensive investigation of the function of these markers can be performed with gene set enrichment analyses, e.g., using kegga or goana from limma. top.markers &lt;- rownames(marker.set)[marker.set$Top &lt;= 10] plotHeatmap(sce, features=top.markers, columns=order(sce$cluster), colour_columns_by=c(&quot;cluster&quot;, &quot;Plate&quot;, &quot;Oncogene&quot;), cluster_cols=FALSE, center=TRUE, symmetric=TRUE, zlim=c(-5, 5)) Figure 12.3: Heatmap of mean-centred and normalized log-expression values for the top set of markers for cluster 1 in the 416B dataset. Column colours represent the cluster to which each cell is assigned, the plate of origin or the oncogene induction status of each cell, as indicated by the legend. Many of the markers in Figure 12.3 are not uniquely up- or downregulated in the chosen cluster. Testing for unique DE tends to be too stringent as it overlooks important genes that are expressed in two or more clusters. For example, in a mixed population of CD4+-only, CD8+-only, double-positive and double-negative T cells, neither Cd4 or Cd8 would be detected as subpopulation-specific markers because each gene is expressed in two subpopulations. With our approach, both of these genes will be picked up as candidate markers as they will be DE between at least one pair of subpopulations. A combination of markers can then be chosen to characterize a subpopulation, which is more flexible than trying to find uniquely DE genes. We strongly recommend selecting some markers for use in validation studies with an independent replicate population of cells. The aim is to identify a corresponding subset of cells that express the upregulated markers and do not express the downregulated markers. Ideally, a different technique for quantifying expression would also be used during validation, e.g., fluorescent in situ hybridisation or quantitative PCR. This confirms that the subpopulation genuinely exists and is not an artifact of scRNA-seq or the computational analysis. Comments from Aaron: By setting direction=&quot;up&quot;, findMarkers will only return genes that are upregulated in each cluster compared to the others. This is convenient in highly heterogeneous populations to focus on genes that can immediately identify each cluster. While lack of expression may also be informative, it is less useful for positive identification. By setting block=, findMarkers() will perform pairwise tests between clusters using only cells on the same plate. It will then combine \\(p\\)-values from different plates using Stouffer’s Z method to obtain a single \\(p\\)-value per gene. An alternative approach is to use linear models via the design= argument - the differences between the two are discussed in the vignette. findMarkers can also be directed to find genes that are DE between the chosen cluster and all other clusters. This should be done by setting pval.type=&quot;all&quot;, which defines the p-value for each gene as the maximum value across all pairwise comparisons involving the chosen cluster. Combined with direction=&quot;up&quot;, this can be used to identify unique markers for each cluster. However, this is sensitive to overclustering, as unique marker genes will no longer exist if a cluster is split into two smaller subclusters. It must be stressed that the (adjusted) p-values computed here cannot be properly interpreted as measures of significance. This is because the clusters have been empirically identified from the data. limma does not account for the uncertainty of clustering, which means that the p-values are much lower than they should be. This is not a concern in other analyses where the groups are pre-defined. The overlapExprs function may also be useful here, to prioritize candidates where there is clear separation between the distributions of expression values of different clusters. This uses the Wilcoxon rank sum test to detect uneven mixing of the distributions of expression values between clusters. By contrast, findMarkers uses t-tests and is primarily concerned with log-fold changes. References "],
["concluding-remarks.html", "Chapter 13 Concluding remarks", " Chapter 13 Concluding remarks Once the basic analysis is completed, it is often useful to save the SingleCellExperiment object to file with the saveRDS function. The object can then be easily restored into new R sessions using the readRDS function. This allows further work to be conducted without having to repeat all of the processing steps described above. saveRDS(file=&quot;416B_data.rds&quot;, sce) A variety of methods are available to perform more complex analyses on the processed expression data. For example, cells can be ordered in pseudotime (e.g., for progress along a differentiation pathway) with monocle (Trapnell et al. 2014) or TSCAN (Ji and Ji 2016); cell-state hierarchies can be characterized with the sincell package (Julia, Telenti, and Rausell 2015); and oscillatory behaviour can be identified using Oscope (Leng et al. 2015). HVGs can be used in gene set enrichment analyses to identify biological pathways and processes with heterogeneous activity, using packages designed for bulk data like topGO or with dedicated single-cell methods like scde (Fan et al. 2016). Full descriptions of these analyses are outside the scope of this workflow, so interested users are advised to consult the relevant documentation. All software packages used in this workflow are publicly available from the Comprehensive R Archive Network (https://cran.r-project.org) or the Bioconductor project (http://bioconductor.org). The specific version numbers of the packages used are shown below, along with the version of the R installation. sessionInfo() ## R version 3.5.0 (2018-04-23) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8 ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] cluster_2.0.7-1 ## [2] dynamicTreeCut_1.63-1 ## [3] limma_3.36.5 ## [4] scran_1.8.4 ## [5] scater_1.8.4 ## [6] ggplot2_3.0.0 ## [7] TxDb.Mmusculus.UCSC.mm10.ensGene_3.4.0 ## [8] GenomicFeatures_1.32.3 ## [9] org.Mm.eg.db_3.6.0 ## [10] AnnotationDbi_1.42.1 ## [11] SingleCellExperiment_1.2.0 ## [12] SummarizedExperiment_1.10.1 ## [13] DelayedArray_0.6.6 ## [14] BiocParallel_1.14.2 ## [15] matrixStats_0.54.0 ## [16] Biobase_2.40.0 ## [17] GenomicRanges_1.32.7 ## [18] GenomeInfoDb_1.16.0 ## [19] IRanges_2.14.12 ## [20] S4Vectors_0.18.3 ## [21] BiocGenerics_0.26.0 ## [22] bindrcpp_0.2.2 ## [23] BiocFileCache_1.4.0 ## [24] dbplyr_1.2.2 ## [25] knitr_1.20 ## [26] BiocStyle_2.8.2 ## ## loaded via a namespace (and not attached): ## [1] Rtsne_0.13 ggbeeswarm_0.6.0 ## [3] colorspace_1.3-2 rjson_0.2.20 ## [5] rprojroot_1.3-2 XVector_0.20.0 ## [7] rstudioapi_0.8 DT_0.4 ## [9] bit64_0.9-7 tximport_1.8.0 ## [11] Rsamtools_1.32.3 pheatmap_1.0.10 ## [13] shinydashboard_0.7.1 shiny_1.1.0 ## [15] BiocManager_1.30.3 compiler_3.5.0 ## [17] httr_1.3.1 backports_1.1.2 ## [19] assertthat_0.2.0 Matrix_1.2-14 ## [21] lazyeval_0.2.1 later_0.7.5 ## [23] htmltools_0.3.6 prettyunits_1.0.2 ## [25] tools_3.5.0 igraph_1.2.2 ## [27] gtable_0.2.0 glue_1.3.0 ## [29] GenomeInfoDbData_1.1.0 reshape2_1.4.3 ## [31] dplyr_0.7.7 rappdirs_0.3.1 ## [33] Rcpp_0.12.19 Biostrings_2.48.0 ## [35] rtracklayer_1.40.6 DelayedMatrixStats_1.2.0 ## [37] xfun_0.4 stringr_1.3.1 ## [39] mime_0.6 statmod_1.4.30 ## [41] XML_3.98-1.16 edgeR_3.22.5 ## [43] zlibbioc_1.26.0 scales_1.0.0 ## [45] hms_0.4.2 promises_1.0.1 ## [47] rhdf5_2.24.0 RColorBrewer_1.1-2 ## [49] yaml_2.2.0 memoise_1.1.0 ## [51] gridExtra_2.3 biomaRt_2.36.1 ## [53] stringi_1.2.4 RSQLite_2.1.1 ## [55] highr_0.7 rlang_0.3.0 ## [57] pkgconfig_2.0.2 bitops_1.0-6 ## [59] evaluate_0.12 lattice_0.20-35 ## [61] purrr_0.2.5 Rhdf5lib_1.2.1 ## [63] bindr_0.1.1 GenomicAlignments_1.16.0 ## [65] htmlwidgets_1.3 labeling_0.3 ## [67] cowplot_0.9.3 bit_1.1-14 ## [69] tidyselect_0.2.5 plyr_1.8.4 ## [71] magrittr_1.5 bookdown_0.7 ## [73] R6_2.3.0 DBI_1.0.0 ## [75] pillar_1.3.0 withr_2.1.2 ## [77] RCurl_1.95-4.11 tibble_1.4.2 ## [79] crayon_1.3.4 KernSmooth_2.23-15 ## [81] rmarkdown_1.10 viridis_0.5.1 ## [83] progress_1.2.0 locfit_1.5-9.1 ## [85] grid_3.5.0 data.table_1.11.8 ## [87] blob_1.1.1 FNN_1.1.2.1 ## [89] digest_0.6.18 xtable_1.8-3 ## [91] httpuv_1.4.5 munsell_0.5.0 ## [93] beeswarm_0.2.3 viridisLite_0.3.0 ## [95] vipor_0.4.5 References "],
["references.html", "Chapter 14 References", " Chapter 14 References "],
["references-1.html", "References", " References "]
]
